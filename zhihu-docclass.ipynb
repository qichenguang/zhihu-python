{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# jieba pathon API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 搜索引擎模式\n",
    "seg_list = jieba.cut_for_search(\"小明硕士毕业于中国科学院计算所，后在日本京都大学深造\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chilist = list(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chilist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 分类器基类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "from pysqlite2 import dbapi2 as sqlite\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 提取特征函数,返回特征字典\n",
    "def separatewords(text):\n",
    "    # 搜索引擎模式\n",
    "    seg_list = jieba.cut_for_search(text)  \n",
    "    words_list = list(seg_list)\n",
    "    words = [s for s in words_list if len(s)>2 ]\n",
    "    return dict([(w,1) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 分类器基类\n",
    "class classifier:\n",
    "    def __init__(self,getfeatures,filename=None):\n",
    "        # Counts of feature/category combinations\n",
    "        # 特征/分类组合： python:{bad:1,good:3}\n",
    "        self.fc = {}\n",
    "        # Counts of documents in each category\n",
    "        # 分类文档数量\n",
    "        self.cc = {}\n",
    "        # 提取特征函数\n",
    "        self.getfeatures = getfeatures\n",
    "        #\n",
    "        self.dbfile = filename\n",
    "\n",
    "    def setdb(self,dbfile):\n",
    "        self.dbfile = dbfile\n",
    "        #\n",
    "        self.con = sqlite.connect(dbfile)    \n",
    "        self.con.execute('create table if not exists fc(feature,category,count)')\n",
    "        self.con.execute('create table if not exists cc(category,count)')\n",
    "        self.con.execute('create index if not exists featureidx on fc(feature)')\n",
    "        self.con.execute('create index if not exists fccategoryidx on fc(category)')\n",
    "        self.con.execute('create index if not exists cccategoryidx on cc(category)')\n",
    "\n",
    "    # 增加 特征/分类组合 数量\n",
    "    def incf(self,f,cat):\n",
    "        if self.dbfile == None:\n",
    "            self.fc.setdefault(f,{})\n",
    "            self.fc[f].setdefault(cat,0)\n",
    "            self.fc[f][cat] += 1\n",
    "        else:\n",
    "            count = self.fcount(f,cat)\n",
    "            if count == 0:\n",
    "                self.con.execute(\"insert into fc values ('%s','%s',1)\" % (f,cat))\n",
    "            else:\n",
    "                self.con.execute(\"update fc set count=%d where feature='%s' and category='%s'\" % (count+1,f,cat)) \n",
    "\n",
    "    # 增加 分类文档 数量\n",
    "    def incc(self,cat):\n",
    "        if self.dbfile == None:\n",
    "            self.cc.setdefault(cat,0)\n",
    "            self.cc[cat] += 1\n",
    "        else:\n",
    "            count = self.catcount(cat)\n",
    "            if count==0:\n",
    "                self.con.execute(\"insert into cc values ('%s',1)\" % (cat))\n",
    "            else:\n",
    "                self.con.execute(\"update cc set count=%d where category='%s'\" % (count+1,cat))  \n",
    "\n",
    "    # 取得 特征/分类组合 数量            \n",
    "    def fcount(self,f,cat):\n",
    "        if self.dbfile == None:\n",
    "            if f in self.fc and cat in self.fc[f]:\n",
    "                return float(self.fc[f][cat])\n",
    "            return 0.0\n",
    "        else:\n",
    "            res = self.con.execute('select count from fc where feature=\"%s\" and category=\"%s\"'%(f,cat)).fetchone()\n",
    "            if res == None: return 0\n",
    "            else: return float(res[0])\n",
    "\n",
    "    # 取得 分类文档 数量    \n",
    "    def catcount(self,cat):\n",
    "        if self.dbfile == None:\n",
    "            if cat in self.cc:\n",
    "                return float(self.cc[cat])\n",
    "            return 0\n",
    "        else:\n",
    "            res = self.con.execute('select count from cc where category=\"%s\"' %(cat)).fetchone()\n",
    "            if res == None: return 0\n",
    "            else: return float(res[0])\n",
    "\n",
    "    # 取得 所有文档 数量    \n",
    "    def totalcount(self):\n",
    "        if self.dbfile == None:\n",
    "            return sum(self.cc.values())\n",
    "        else:\n",
    "            res = self.con.execute('select sum(count) from cc').fetchone();\n",
    "            if res == None: return 0\n",
    "            return res[0]\n",
    "\n",
    "    # 取得 所有分类的列表\n",
    "    def categories(self):\n",
    "        if self.dbfile == None:\n",
    "            return self.cc.keys()\n",
    "        else:\n",
    "            cur = self.con.execute('select category from cc');\n",
    "            return [d[0] for d in cur]\n",
    "\n",
    "    # 训练函数\n",
    "    def train(self,item,cat):\n",
    "        features = self.getfeatures(item)\n",
    "        # Increment the count for every feature with this category\n",
    "        for f in features:\n",
    "            self.incf(f,cat)\n",
    "\n",
    "        # Increment the count for this category\n",
    "        self.incc(cat)\n",
    "\n",
    "        #\n",
    "        if self.dbfile != None:\n",
    "            self.con.commit()\n",
    "\n",
    "    # 特征分类概率 = 特征在分类下数量 / 分类文档总数量\n",
    "    # 因为分类函数返回的是字典，所以 (特征在分类下数量) <= (分类文档总数量)\n",
    "    # (python | good) <= (good) == ( python|good + snake|good + programmer|good + ...)\n",
    "    def fprob(self,f,cat):\n",
    "        if self.catcount(cat)==0: return 0\n",
    "\n",
    "        # The total number of times this feature appeared in this \n",
    "        # category divided by the total number of items in this category\n",
    "        return self.fcount(f,cat)/self.catcount(cat)   \n",
    "\n",
    "    # 加权概率 【特征,分类,特征概率函数,假设概率权重,假设概率值】\n",
    "    # 防止没有遇见的特征分类值为零,预加了 (假设概率权重 * 假设概率值)\n",
    "    # 让没有见过的特征分类值保持近似中性，有一个计算后的加权概率值\n",
    "    def weightedprob(self,f,cat,prf,weight=1.0,ap=0.5):\n",
    "        # Calculate current probability\n",
    "        basicprob = prf(f,cat)\n",
    "        #print 'basicprob:',basicprob\n",
    "        # Count the number of times this feature has appeared in\n",
    "        # all categories\n",
    "        # 特征在所有分类下的总量\n",
    "        # 即包含特征的文章总数\n",
    "        totals = sum([self.fcount(f,c) for c in self.categories()])\n",
    "        #print 'totals:',totals\n",
    "\n",
    "        # Calculate the weighted average\n",
    "        # ((假设权重 * 假设概率) + (特征分类概率 * 特征文章总数) / ( 假设权重 + 特征文章总数)\n",
    "        #  因 假设概率 <=1 , 特征分类概率 <=1 , 所以 该公式结果 <=1\n",
    "        bp = ((weight * ap) + (totals * basicprob))/(weight + totals)\n",
    "        return bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_and_parse_file(file_path):\n",
    "    # 去掉标点符号\n",
    "    delset = string.punctuation\n",
    "    try:\n",
    "        if os.path.exists(file_path):\n",
    "            f = open(file_path, \"r\")\n",
    "            lines = f.readlines()\n",
    "            f.close()\n",
    "            if len(lines) < 5:\n",
    "                return None,None,0,None,None\n",
    "            title = lines[0].strip()\n",
    "            fields = lines[2].split(':')\n",
    "            zhan_num = int(fields[2].strip())\n",
    "            author = fields[1].strip().split(' ')[0].strip()\n",
    "            content = ''.join(lines[5:-2])\n",
    "            url = lines[-1].split(' ')[1].strip()\n",
    "            #\n",
    "            title = title.translate(None,delset)\n",
    "            author = author.translate(None,delset)\n",
    "            content = content.translate(None,delset)\n",
    "            return title,author,zhan_num,url,content\n",
    "    except IOError:\n",
    "        error_file_path = file_path\n",
    "        print \"error_file_path:\" , error_file_path\n",
    "    \n",
    "    # 默认\n",
    "    return None,None,0,None,None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 监督学习训练函数\n",
    "def sampletrain(cl,rootdir):\n",
    "    i = 0\n",
    "    for parent,dirnames,filenames in os.walk(rootdir):  \n",
    "        #输出文件信息\n",
    "        for filename in filenames:                        \n",
    "            #print \"parent is:\" + parent\n",
    "            #print type(parent)\n",
    "            #print \"filename is: \" + str(filename).decode('gbk', 'ignore')\n",
    "            #输出文件路径信息\n",
    "            #print \"the full name of the file is:\" + os.path.join(parent,filename) \n",
    "            file_class = parent.split(\"\\\\\")[1]\n",
    "            #print file_class\n",
    "            full_name = os.path.join(parent,filename) \n",
    "            i += 1\n",
    "            print str(i) + \" ,full_name is \" + str(full_name).decode('gbk', 'ignore')\n",
    "            # 读取文件\n",
    "            title,author,zhan_num,url,content = read_and_parse_file(full_name)\n",
    "            if title == None:\n",
    "                continue\n",
    "            #\n",
    "            cl.train(\"%s %s %s\" % (str(title),str(author),str(content)),file_class.decode('gbk', 'ignore')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootdir = 'E:/project/pychram/zhihu/zhihu-python/text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl = classifier(separatewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampletrain(cl,rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl.train('the quick brown fox jump over the lazy dog','good')\n",
    "cl.train('make quick money in the on1ine casio ','bad')\n",
    "cl.fcount('quick' , 'good')\n",
    "cl.catcount('good')\n",
    "cl.catcount('bad')\n",
    "cl.totalcount()\n",
    "cl.fcount('the' , 'good')\n",
    "cl.fc\n",
    "sampletrain(cl)\n",
    "cl.fprob('quick','good')\n",
    "cl.weightedprob('money','good',cl.fprob)\n",
    "cl.fprob('money','good')\n",
    "cl.weightedprob('money','good',cl.fprob)\n",
    "cl.fprob('money','bad')\n",
    "cl.weightedprob('money','bad',cl.fprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.totalcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.fc['台北市'.decode('UTF-8','ignore')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.fprob('台北市'.decode('UTF-8','ignore'),'百科'.decode('UTF-8','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.weightedprob('台北市'.decode('UTF-8','ignore'),'百科'.decode('UTF-8','ignore'),cl.fprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.weightedprob('台北市'.decode('UTF-8','ignore'),'IT'.decode('UTF-8','ignore'),cl.fprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.weightedprob('台北市'.decode('UTF-8','ignore'),'Python'.decode('UTF-8','ignore'),cl.fprob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.fprob('台北市'.decode('UTF-8','ignore'),'Python'.decode('UTF-8','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.fprob('Ironymode','IT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.fc['台北市'.decode('UTF-8','ignore')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class naivebayes(classifier):\n",
    "    # P(分类|文档) = P(文档|分类) * P(分类) / P(文档)\n",
    "    def __init__(self,getfeatures):\n",
    "        classifier.__init__(self,getfeatures)\n",
    "        self.thresholds = {}\n",
    "\n",
    "    # 各个特征分类概率连乘作为文档分类概率 \n",
    "    # (f1|cate * f2|cate * f2|cate * ...) == P(文档|分类)\n",
    "    def docprob(self,item,cat):\n",
    "        features = self.getfeatures(item)   \n",
    "\n",
    "        # Multiply the probabilities of all the features together\n",
    "        p = 1\n",
    "        for f in features: p *= self.weightedprob(f,cat,self.fprob)\n",
    "        return p     \n",
    "\n",
    "    # P(分类|文档) = (分类文档数量/文档总数) * 文档分类概率 / 文档总数\n",
    "    def prob(self,item,cat):\n",
    "        # 分类概率 = (分类文档数量/文档总数) == P(分类)  \n",
    "        catprob = self.catcount(cat)/self.totalcount()\n",
    "        # 文档分类概率 = P(文档|分类)\n",
    "        docprob = self.docprob(item,cat)\n",
    "        return docprob * catprob    \n",
    "\n",
    "    # 设置分类的阀值\n",
    "    def setthreshold(self,cat,t):\n",
    "        self.thresholds[cat]=t\n",
    "\n",
    "    # 取得分类的阀值,默认 1:1\n",
    "    def getthreshold(self,cat):\n",
    "        if cat not in self.thresholds: return 1.0\n",
    "        return self.thresholds[cat]  \n",
    "\n",
    "    # 查找分类\n",
    "    def classify(self,item,default=None):\n",
    "        probs = {}\n",
    "        # Find the category with the highest probability\n",
    "        max = 0.0\n",
    "        for cat in self.categories():\n",
    "            probs[cat] = self.prob(item,cat)\n",
    "            if probs[cat] > max: \n",
    "                max = probs[cat]\n",
    "                best = cat\n",
    "\n",
    "        # best 目前是最大可能性的分类\n",
    "        # Make sure the probability exceeds threshold*next best\n",
    "        for cat in probs:\n",
    "            if cat == best: continue\n",
    "            # 最佳分类 < (其他任何分类 * 最佳分类阀值) \n",
    "            # 不能当作最佳分类，返回 默认分类             \n",
    "            if probs[cat] * self.getthreshold(best) > probs[best]: return default\n",
    "\n",
    "        # 最佳分类 >= (其他任何分类 * 最佳分类阀值) \n",
    "        # 返回最佳分类\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = naivebayes(separatewords)\n",
    "sampletrain(cl,rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.prob('台北市'.decode('UTF-8','ignore'),'百科'.decode('UTF-8','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.prob('台北市'.decode('UTF-8','ignore'),'IT'.decode('UTF-8','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "judge = cl.classify('怎样区分罗氏虾、基围虾、大头虾、青虾、九节虾、花虾、竹节虾、对虾、沙虾、虎虾……各种虾 又称烟熏食品香精 烟熏调味品可分为原生型和派生型两大类 但传统烟熏法温度很难控制 怎样区分大闸蟹、毛蟹、青蟹、梭子蟹、河蟹、红鲟、螃蜞，帝王蟹，松叶蟹等等螃蟹'.decode('UTF-8','ignore'),default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "judge = cl.classify('''\n",
    "支付意愿法。简单说，就是研究者进行问卷调查统计，如果能够减少你百分之一的死亡率，你愿意付多少钱？这个方法算出来的数字普遍比第一种要高，不过人们在回答问卷时对假想风险的评定往往与面临真实死亡风险时的反映有所不同，所以可能不如第一种客观。\n",
    "\n",
    "第三种方法是人力资本价值法。也就是开头提到的按工资来计算人命价值。这个方法的最大缺陷是低估了人的生命价值，因为生命的意义不仅仅是工作和赚工资。比如一个乞丐一生没有收入，他的生命是不是就没有价值呢？显然不是。\n",
    "\n",
    "为生命定价的主要目的是用于政策研究。比如，美国官方各个部门对生命的定价都不一样，美国环保部的定价是910万，食品药品监督局是790万，交通部是940万。以这个定价为标准，很多政策就很容易决定。比如修缮高速公路可以减少10个交通事故死亡人数，需要花1亿美元，交通部一算，十个人值9400万美元，就不会去修这条路。\n",
    "\n",
    "问题中的法国巴黎人和叙利亚人，生命价格必然是不一样的。考虑到美国和中国的人命价格差距已经相差约50倍，那么法国首都和叙利亚前线的人命价格恐怕相差会更多。\n",
    "\n",
    "你看，人的生命在经济学家眼里比法律工作者那里更贵。而比起政客来，大家都显得情深意重。举个例子，大家都知道烟草对身体有害，吸烟致男性平均减寿7.13年，女性平均减寿4.5年。有人说，不禁烟是因为国家需要收税，可是事实上，政府在烟草上的税收，是少于因为吸烟造成的医疗开销和生产率损失的。那么，既然对健康不利同时又消耗医疗资源，为什么政府不干脆禁烟呢？\n",
    "\n",
    "\n",
    "''',default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.prob('台北市'.decode('UTF-8','ignore'),'人生'.decode('UTF-8','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.prob('台北市'.decode('UTF-8','ignore'),'百科'.decode('UTF-8','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.prob('熏肉'.decode('UTF-8','ignore'),'人生'.decode('UTF-8','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.prob('又称烟熏食品香精'.decode('UTF-8','ignore'),'食品'.decode('UTF-8','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class fisherclassifier(classifier):\n",
    "\n",
    "    def __init__(self,getfeatures):\n",
    "        classifier.__init__(self,getfeatures)\n",
    "        self.minimums = {}\n",
    "\n",
    "    # 特征概率\n",
    "    def cprob(self,f,cat):\n",
    "        # The frequency of this feature in this category    \n",
    "        # 特征分类概率 = 特征在分类下数量 / 分类文档总数量\n",
    "        clf = self.fprob(f,cat)\n",
    "        if clf==0: return 0\n",
    "\n",
    "        # The frequency of this feature in all the categories\n",
    "        # 特征在所有分类下的总概率\n",
    "        freqsum = sum([self.fprob(f,c) for c in self.categories()])\n",
    "\n",
    "        # The probability is the frequency in this category divided by\n",
    "        # the overall frequency\n",
    "        # 特征分类概率 / 特征在所有分类下的总概率\n",
    "        p = clf/(freqsum)\n",
    "\n",
    "        return p\n",
    "\n",
    "\n",
    "    def fisherprob(self,item,cat):\n",
    "        # Multiply all the probabilities together\n",
    "        p = 1\n",
    "        features = self.getfeatures(item)\n",
    "        for f in features:\n",
    "            p *= (self.weightedprob(f,cat,self.cprob))\n",
    "\n",
    "        # Take the natural log and multiply by -2\n",
    "        fscore=-2*math.log(p)\n",
    "\n",
    "        # Use the inverse chi2 function to get a probability\n",
    "        return self.invchi2(fscore,len(features)*2)\n",
    "\n",
    "    # 对数卡方分布\n",
    "    def invchi2(self,chi, df):\n",
    "        m = chi / 2.0\n",
    "        sum = term = math.exp(-m)\n",
    "        for i in range(1, df//2):\n",
    "            term *= m / i\n",
    "            sum += term\n",
    "        return min(sum, 1.0)    \n",
    "\n",
    "    def setminimum(self,cat,min):\n",
    "        self.minimums[cat] = min\n",
    "\n",
    "    def getminimum(self,cat):\n",
    "        if cat not in self.minimums: return 0\n",
    "        return self.minimums[cat]\n",
    "\n",
    "    # 概率独立,满足对数卡方分布\n",
    "    # 如果出现大概率高的值，该分类为最佳分类\n",
    "    def classify(self,item,default=None):\n",
    "        # Loop through looking for the best result\n",
    "        best = default\n",
    "        max = 0.0\n",
    "        for c in self.categories():\n",
    "            p = self.fisherprob(item,c)\n",
    "            # Make sure it exceeds its minimum\n",
    "            if p > self.getminimum(c) and p > max:\n",
    "                best = c\n",
    "                max = p\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = fisherclassifier(separatewords)\n",
    "sampletrain(cl,rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.cprob('台北市'.decode('UTF-8','ignore'),'百科'.decode('UTF-8','ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.cprob('台北市'.decode('UTF-8','ignore'),'IT'.decode('UTF-8','ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.cprob('台北市'.decode('UTF-8','ignore'),'人生'.decode('UTF-8','ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.cprob('熏肉'.decode('UTF-8','ignore'),'人生'.decode('UTF-8','ignore'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl.cprob('又称烟熏食品香精'.decode('UTF-8','ignore'),'食品'.decode('UTF-8','ignore'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "judge = cl.classify('怎样区分罗氏虾、基围虾、大头虾、青虾、九节虾、花虾、竹节虾、对虾、沙虾、虎虾……各种虾 又称烟熏食品香精 烟熏调味品可分为原生型和派生型两大类 但传统烟熏法温度很难控制 怎样区分大闸蟹、毛蟹、青蟹、梭子蟹、河蟹、红鲟、螃蜞，帝王蟹，松叶蟹等等螃蟹'.decode('UTF-8','ignore'),default='unknown')\n",
    "print judge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "judge = cl.classify('''\n",
    "支付意愿法。简单说，就是研究者进行问卷调查统计，如果能够减少你百分之一的死亡率，你愿意付多少钱？这个方法算出来的数字普遍比第一种要高，不过人们在回答问卷时对假想风险的评定往往与面临真实死亡风险时的反映有所不同，所以可能不如第一种客观。\n",
    "\n",
    "第三种方法是人力资本价值法。也就是开头提到的按工资来计算人命价值。这个方法的最大缺陷是低估了人的生命价值，因为生命的意义不仅仅是工作和赚工资。比如一个乞丐一生没有收入，他的生命是不是就没有价值呢？显然不是。\n",
    "\n",
    "为生命定价的主要目的是用于政策研究。比如，美国官方各个部门对生命的定价都不一样，美国环保部的定价是910万，食品药品监督局是790万，交通部是940万。以这个定价为标准，很多政策就很容易决定。比如修缮高速公路可以减少10个交通事故死亡人数，需要花1亿美元，交通部一算，十个人值9400万美元，就不会去修这条路。\n",
    "\n",
    "问题中的法国巴黎人和叙利亚人，生命价格必然是不一样的。考虑到美国和中国的人命价格差距已经相差约50倍，那么法国首都和叙利亚前线的人命价格恐怕相差会更多。\n",
    "\n",
    "你看，人的生命在经济学家眼里比法律工作者那里更贵。而比起政客来，大家都显得情深意重。举个例子，大家都知道烟草对身体有害，吸烟致男性平均减寿7.13年，女性平均减寿4.5年。有人说，不禁烟是因为国家需要收税，可是事实上，政府在烟草上的税收，是少于因为吸烟造成的医疗开销和生产率损失的。那么，既然对健康不利同时又消耗医疗资源，为什么政府不干脆禁烟呢？\n",
    "\n",
    "\n",
    "''',default='unknown')\n",
    "print judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "judge = cl.classify('熏肉'.decode('UTF-8','ignore'),default='unknown')\n",
    "print judge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 共用数据库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = fisherclassifier(separatewords)\n",
    "cl.setdb('zhihu-fisher.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampletrain(cl,rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sampletrain(cl)\n",
    "cl.cprob('quick','good')\n",
    "cl.cprob('money','good')\n",
    "cl.cprob('money','bad')\n",
    "cl.weightedprob('money','bad',cl.cprob)\n",
    "cl.fisherprob('money','good')\n",
    "cl.fisherprob('money','bad')\n",
    "\n",
    "cl.classify('quick rabbit')\n",
    "cl.classify('quick money')\n",
    "\n",
    "cl.setminimum('bad',0.8)\n",
    "cl.classify('quick money')\n",
    "\n",
    "cl.setminimum('good',0.4)\n",
    "cl.classify('quick rabbit')\n",
    "\n",
    "cl = fisherclassifier(getwords)\n",
    "cl.setdb('fisher.db')\n",
    "sampletrain(cl)\n",
    "\n",
    "c2 = naivebayes(getwords)\n",
    "c2.setdb('fisher.db')\n",
    "c2.classify('quick money')\n",
    "cl.classify('quick money')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = naivebayes(separatewords)\n",
    "cl.setdb('zhihu-fisher.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
